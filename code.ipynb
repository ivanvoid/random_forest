{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZQD8NqPhKyBP"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score # Please note that this is the only sklearn function that can be utilized."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YV1MHt_VTg9f"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "a1vkTOD6K5Nj"
      },
      "outputs": [],
      "source": [
        "# Load the train/val/test dataset\n",
        "\n",
        "df_train = pd.DataFrame(pd.read_csv(\"./PR_HW3_Train.csv\"))\n",
        "df_val   = pd.DataFrame(pd.read_csv(\"./PR_HW3_Val.csv\"))\n",
        "df_test  = pd.DataFrame(pd.read_csv(\"./PR_HW3_Test.csv\"))\n",
        "\n",
        "X_train = df_train[['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5', 'Feature6', 'Feature7']].to_numpy()\n",
        "y_train = df_train[\"Target\"].to_numpy()\n",
        "\n",
        "X_val = df_val[['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5', 'Feature6', 'Feature7']].to_numpy()\n",
        "y_val = df_val[\"Target\"].to_numpy()\n",
        "\n",
        "X_test = df_test[['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5', 'Feature6', 'Feature7']].to_numpy()\n",
        "y_test = df_test[\"Target\"].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MJcktFIuK78Y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(800, 7)\n",
            "(800,)\n",
            "(800, 7)\n",
            "(800,)\n",
            "(800, 7)\n",
            "(800,)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa3hnJ9sTkvh"
      },
      "source": [
        "# Model Implementation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$$gini = 1 - \\sum_{i=1}^{C}(p_i)^2$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math \n",
        "\n",
        "def get_probabilities(sequence):\n",
        "    unique_y = np.unique(sequence)\n",
        "    count_y = {}\n",
        "    for u in sequence:\n",
        "        if u in count_y:\n",
        "            count_y[u] += 1\n",
        "        else:\n",
        "            count_y[u] = 1\n",
        "\n",
        "    N = len(sequence)\n",
        "    for k,v in count_y.items():\n",
        "        count_y[k] = v / N\n",
        "\n",
        "    probabilities = np.array(list(count_y.values()))\n",
        "    \n",
        "    if not math.isclose(np.sum(probabilities),1):\n",
        "        raise AssertionError(np.sum(probabilities))\n",
        "\n",
        "    return probabilities\n",
        "\n",
        "\n",
        "seq = np.array([0,0,0,0,1,1,1,1,1,1])\n",
        "assert np.all(get_probabilities(seq) == np.array([0.4, 0.6]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def entropy(sequence):\n",
        "    probabilities = get_probabilities(sequence)\n",
        "    \n",
        "    entropy = np.sum(-probabilities * np.log2(probabilities+1e-9))\n",
        "\n",
        "    return entropy\n",
        "\n",
        "assert not np.isclose(entropy(seq), 0.97)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gini(sequence):\n",
        "    probabilities = get_probabilities(sequence)\n",
        "    \n",
        "    return 1 - (probabilities**2).sum()\n",
        "\n",
        "assert gini(seq) == 0.48"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cart_info_gain(feature_x, value, y, func=gini):\n",
        "    left_mask = feature_x <= value\n",
        "    right_mask= feature_x >  value\n",
        "\n",
        "    left_y = y[left_mask]\n",
        "    right_y= y[right_mask]\n",
        "\n",
        "    if left_y.size == 0 or right_y.size == 0:\n",
        "        return 1e+9\n",
        "    \n",
        "    left = func(left_y)\n",
        "    right= func(right_y)\n",
        "\n",
        "    p = left_y.size / y.size\n",
        "\n",
        "    # return total - p*left - (1-p)*right\n",
        "    return p*left + (1-p)*right \n",
        "\n",
        "feature_x = np.array(\n",
        "    [1,2,1,2, 3,4,3,3,3])\n",
        "y = np.array(\n",
        "    [0,1,0,1, 0,0,0,1,0])\n",
        "value = 2\n",
        "\n",
        "# feature_x = np.array(\n",
        "#     [1,2,1,2, 3,4,3,3,3])\n",
        "# y = np.array(\n",
        "#     [0,1,0,1, 0,0,0,1,0])\n",
        "# value = 4\n",
        "\n",
        "value_gini = cart_info_gain(feature_x, value, y, gini) \n",
        "assert not np.isclose(value_gini, 0.39)\n",
        "# value_gini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_best_split_params(X,y,func=gini):\n",
        "\n",
        "    best_info_gain = 1e+9\n",
        "    best_feature_idx = None\n",
        "    best_split_value = None\n",
        "\n",
        "    for feature_idx in range(X.shape[1]):\n",
        "        feature_x = X[:, feature_idx] \n",
        "        \n",
        "        unique_x = np.unique(feature_x)\n",
        "        sorted_unique_x = sorted(unique_x)\n",
        "        mean_x = []\n",
        "        for i in range(len(sorted_unique_x)-1):\n",
        "            mean_x += [(unique_x[i+1] + unique_x[i]) / 2]\n",
        "\n",
        "        for value in mean_x:\n",
        "\n",
        "            gain_info = cart_info_gain(feature_x, value, y, func)\n",
        "            # print(value, gain_info), #'\\t', total_value - info)\n",
        "\n",
        "            if gain_info < best_info_gain:\n",
        "                best_info_gain = gain_info\n",
        "                best_feature_idx = feature_idx\n",
        "                best_split_value = value\n",
        "    return best_feature_idx, best_split_value, best_info_gain\n",
        "\n",
        "X = np.array([\n",
        "    [1],\n",
        "    [2],\n",
        "    [3],\n",
        "    [4],\n",
        "    [5],\n",
        "    [6]\n",
        "    ])\n",
        "y = np.array([1,1,1,1,0,0])\n",
        "\n",
        "\n",
        "best_idx, best_value, best_gain = get_best_split_params(X, y)\n",
        "# print(best_idx, best_value, best_gain)\n",
        "assert best_value == 4.5\n",
        "assert best_gain == 0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_data(X,y,feature_idx,value):\n",
        "    feature = X[:,feature_idx] \n",
        "\n",
        "    mask_l = feature <= value\n",
        "    mask_r = feature >  value\n",
        "\n",
        "    X_l = X[mask_l]\n",
        "    X_r = X[mask_r]\n",
        "\n",
        "    y_l = y[mask_l]\n",
        "    y_r = y[mask_r]\n",
        "\n",
        "    return X_l, X_r, y_l, y_r\n",
        "\n",
        "X_l, X_r, y_l, y_r = split_data(X, y, best_idx, best_value)\n",
        "# X_l.shape, X_r.shape, y_l.shape, y_r.shape\n",
        "# X_l, X_r, y_l, y_r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TreeNode to build a tree\n",
        "class TreeNode():\n",
        "    def __init__(self, parent_node):\n",
        "        self.parent = parent_node\n",
        "\n",
        "        self.child_left = None\n",
        "        self.child_right = None\n",
        "\n",
        "        self.split_feature_idx = None\n",
        "        self.split_value = None\n",
        "\n",
        "        self.prediction = None\n",
        "        self.info_gain = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_tree(X,y,node,criterion=gini,max_depth=3,depth=0):\n",
        "    node = TreeNode(node)\n",
        "    \n",
        "    # if only one class or X is the same values\n",
        "    y_unique = np.unique(y.astype(np.int32)) \n",
        "    # This must be 1, if features are the same\n",
        "    x_unique = np.sum([np.unique(X[:,i]).size for i in range(X.shape[1])]) / X.shape[1] \n",
        "    # print(y_unique, y_unique.size, nfeature-1)\n",
        "    if y_unique.size == 1 or x_unique == 1:\n",
        "    # if y_unique.size == 1:\n",
        "        node.prediction = np.argmax(np.bincount(y.astype(np.int32)))\n",
        "        return node\n",
        "\n",
        "    if depth >= max_depth:\n",
        "        node.prediction = np.argmax(np.bincount(y.astype(np.int32)))\n",
        "        return node\n",
        "\n",
        "    best_idx, best_value, best_gain = get_best_split_params(X, y, criterion)\n",
        "    node.split_feature_idx = best_idx\n",
        "    node.split_value = best_value\n",
        "    node.info_gain = best_gain\n",
        "\n",
        "    # if np.isclose(best_value, 0.9775) and  np.isclose(best_gain, 0.3333333333333333):\n",
        "    #     print('will brake')\n",
        "\n",
        "    X_l, X_r, y_l, y_r = split_data(X, y, best_idx, best_value)\n",
        "    \n",
        "    # print(best_gain, best_idx, best_value)\n",
        "    # print(X_l.shape, X_r.shape, y_l.shape, y_r.shape)\n",
        "\n",
        "    node.child_left = build_tree(X_l, y_l, node, criterion, max_depth, depth+1)\n",
        "    node.child_right = build_tree(X_r, y_r, node, criterion, max_depth, depth+1)\n",
        "    \n",
        "    return node\n",
        "    \n",
        "X = np.array([\n",
        "    [1],\n",
        "    [2],\n",
        "    [3],\n",
        "    [4],\n",
        "    [5],\n",
        "    [6],\n",
        "])\n",
        "y = np.array([0,1,2,0,1,2])\n",
        "\n",
        "root = build_tree(X, y, None, gini, 3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rec_prediction(sample, node):\n",
        "    if node.child_left is None or node.child_right is None:\n",
        "        return node.prediction\n",
        "    \n",
        "    if sample[node.split_feature_idx] <= node.split_value:\n",
        "        # print('go left')\n",
        "        node = node.child_left\n",
        "    else:\n",
        "        # print('go right')\n",
        "        node = node.child_right\n",
        "\n",
        "    prediction = rec_prediction(sample, node)\n",
        "\n",
        "    return prediction\n",
        "\n",
        "# for i in range(6):\n",
        "#     x = X[i]\n",
        "#     _y = int(y[i])\n",
        "#     y_hat = rec_prediction(x, root)\n",
        "#     print(_y, y_hat)\n",
        "    \n",
        "# root = build_tree(X_train, y_train, None, gini, 3, 0)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Importance\n",
        "sum of the improvments(information_gains) in all nodes where feature used as splitter\n",
        "'''\n",
        "\n",
        "def feature_importance(collector, node):\n",
        "    # print(collector)\n",
        "    if node.child_left is None or node.child_right is None:\n",
        "        return\n",
        "    \n",
        "    if node.split_feature_idx in collector:\n",
        "        collector[node.split_feature_idx] += 1 #node.info_gain\n",
        "    else:\n",
        "        collector[node.split_feature_idx] = 1 #node.info_gain\n",
        "\n",
        "    feature_importance(collector, node.child_left)\n",
        "    feature_importance(collector, node.child_right)\n",
        "\n",
        "    return collector\n",
        "\n",
        "# node = root\n",
        "# node.split_feature_idx, node.info_gain\n",
        "\n",
        "# collector = {}\n",
        "# feature_importance(collector, root)\n",
        "# print('-'*24)\n",
        "# print(collector)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DecisionTree():\n",
        "    def __init__(self, criterion='gini', max_depth=None, max_features=None):\n",
        "        \n",
        "        if criterion == 'gini':\n",
        "            self.criterion = gini\n",
        "        elif criterion == 'entropy':\n",
        "            self.criterion = entropy\n",
        "        \n",
        "        if max_depth is None:\n",
        "            self.max_depth = 1e9\n",
        "        else:\n",
        "            self.max_depth = max_depth\n",
        "\n",
        "        self.importance = {}\n",
        "\n",
        "    def fit(self, X, y, sample_weight=None):\n",
        "        self.root = build_tree(X, y, None, self.criterion, self.max_depth, 0)\n",
        "\n",
        "    def predict(self, X):\n",
        "        n_samples, n_features = X.shape\n",
        "        y_pred = []\n",
        "        for n in range(n_samples):\n",
        "            predicted_class = rec_prediction(X[n], self.root)\n",
        "            y_pred += [predicted_class]\n",
        "        return np.array(y_pred)\n",
        "            \n",
        "\n",
        "    def countImportance(self):\n",
        "        collector = {}\n",
        "        feature_importance(collector, self.root)\n",
        "        self.importance = collector "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "BE8wu0MGN_H-"
      },
      "outputs": [],
      "source": [
        "class RandomForest():\n",
        "    \"\"\"\n",
        "        You can add/change any variables/methods to meet your need.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_estimators=10, max_features=None, boostrap=True, criterion='gini', max_depth=None):\n",
        "        \n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_features = max_features\n",
        "        self.boostrap = boostrap\n",
        "        self.criterion = criterion\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "        self.tree_features = []\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        self.estimatiors = []\n",
        "\n",
        "        for _ in range(self.n_estimators):\n",
        "\n",
        "            if self.max_features:\n",
        "                n_features = round(self.max_features)\n",
        "                sample_features = np.random.choice(range(X.shape[1]), n_features, replace=False)\n",
        "            else:\n",
        "                rand_feature = np.random.randint(2, n_features)\n",
        "                sample_features = np.random.choice(range(X.shape[1]), rand_feature, replace=False)\n",
        "\n",
        "            # Different samples\n",
        "            \n",
        "        \n",
        "            sample_idxs = np.random.choice(range(X.shape[0]), n_samples)#, replace=False)\n",
        "            \n",
        "            # save feature number\n",
        "            self.tree_features += [sample_features]\n",
        "\n",
        "            # genearte new data\n",
        "            sampled_X = X[sample_idxs]\n",
        "            sampled_X = sampled_X[:, sample_features]\n",
        "            sampled_y = y[sample_idxs]\n",
        "\n",
        "            # Train trees\n",
        "            dtree = DecisionTree(self.criterion, self.max_depth, self.max_features)\n",
        "            dtree.fit(sampled_X, sampled_y)\n",
        "\n",
        "            self.estimatiors += [dtree]\n",
        "\n",
        "    def predict(self, X):\n",
        "        # majority vote\n",
        "\n",
        "        n_predictions = []\n",
        "\n",
        "        for n in range(self.n_estimators):\n",
        "\n",
        "            feature_idx = self.tree_features[n]\n",
        "\n",
        "            y_pred = self.estimatiors[n].predict(X[:,feature_idx])\n",
        "            # print(y_pred)\n",
        "            n_predictions += [y_pred]\n",
        "\n",
        "        # print(n_predictions)\n",
        "\n",
        "        preds = np.concatenate([x.reshape(1,-1) for x in n_predictions], axis=0)\n",
        "        \n",
        "        votes = []\n",
        "\n",
        "        for p in preds.T:\n",
        "            # print(p, np.argmax(np.bincount(p)))\n",
        "            vote = np.argmax(np.bincount(p))\n",
        "            votes += [vote]\n",
        "\n",
        "        return np.array(votes)\n",
        "\n",
        "# For Q7-2, validation accuracy should be higher than or equal to 0.86\n",
        "\n",
        "# np.random.seed(0)\n",
        "\n",
        "# rf_maxfeature_none = RandomForest(n_estimators=10, max_features=None, boostrap=True, criterion='gini', max_depth=None)\n",
        "# rf_maxfeature_none.fit(X_train, y_train)\n",
        "\n",
        "# print(\"Q7-1 max_features='All': \", accuracy_score(y_val, rf_maxfeature_none.predict(X_val)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPUsaCh2T9Fs"
      },
      "source": [
        "# Questions for Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zSB-Uqp4OaaX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['+' '+' '+' '+' '+' '-']: entropy = 0.6500224187629642\n",
            "['+' '+' '+' '-' '-' '-']: entropy = 0.99999999711461\n",
            "['+' '-' '-' '-' '-' '-']: entropy = 0.6500224187629642\n",
            "\n",
            "['+' '+' '+' '+' '+' '-']: gini index = 0.2777777777777777\n",
            "['+' '+' '+' '-' '-' '-']: gini index = 0.5\n",
            "['+' '-' '-' '-' '-' '-']: gini index = 0.2777777777777777\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# For Q1\n",
        "ex1 = np.array([\"+\", \"+\", \"+\", \"+\", \"+\", \"-\"])\n",
        "ex2 = np.array([\"+\", \"+\", \"+\", \"-\", \"-\", \"-\"])\n",
        "ex3 = np.array([\"+\" ,\"-\", \"-\", \"-\", \"-\", \"-\"])\n",
        "\n",
        "print(f\"{ex1}: entropy = {entropy(ex1)}\\n{ex2}: entropy = {entropy(ex2)}\\n{ex3}: entropy = {entropy(ex3)}\\n\")\n",
        "print(f\"{ex1}: gini index = {gini(ex1)}\\n{ex2}: gini index = {gini(ex2)}\\n{ex3}: gini index = {gini(ex3)}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "G_t9N9fnOdon"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q2-1 max_depth=3:  0.73125\n"
          ]
        }
      ],
      "source": [
        "# For Q2-1, validation accuracy should be higher than or equal to 0.73\n",
        "\n",
        "np.random.seed(0) # You may adjust the seed number in all the cells\n",
        "\n",
        "dt_depth3 = DecisionTree(criterion='gini', max_features=None, max_depth=3)\n",
        "dt_depth3.fit(X_train, y_train, sample_weight=None)\n",
        "\n",
        "acc = accuracy_score(y_val, dt_depth3.predict(X_val))\n",
        "\n",
        "print(\"Q2-1 max_depth=3: \", acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "T0HcgzMdjHRP"
      },
      "outputs": [],
      "source": [
        "\"\"\" Do Not Modify Below \"\"\"\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier as SK_DecisionTreeClassifier\n",
        "\n",
        "sk_dt = SK_DecisionTreeClassifier(criterion='gini', max_depth=3)\n",
        "sk_dt.fit(X_train, y_train)\n",
        "sk_acc = accuracy_score(y_val, sk_dt.predict(X_val))\n",
        "\n",
        "assert round(acc, 3) == round(sk_acc, 3), \"Because the Decision Tree without any trick has a fixed answer, your accuracy should be the same as sklearn, otherwise your implementation might have some problems\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "SjCPMr-eQ7jn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q2-2 max_depth=10:  0.86125\n"
          ]
        }
      ],
      "source": [
        "# For Q2-2, validation accuracy should be higher than or equal to 0.85\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "dt_depth10 = DecisionTree(criterion='gini', max_features=None, max_depth=10)\n",
        "dt_depth10.fit(X_train, y_train, sample_weight=None)\n",
        "\n",
        "print(\"Q2-2 max_depth=10: \", accuracy_score(y_val,  dt_depth10.predict(X_val)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "iTbxGPrbO2jT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q3-1 criterion='gini':  0.73125\n"
          ]
        }
      ],
      "source": [
        "# For Q3-1, validation accuracy should be higher than or equal to 0.73\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "dt_gini = DecisionTree(criterion='gini', max_features=None, max_depth=3)\n",
        "dt_gini.fit(X_train, y_train, sample_weight=None)\n",
        "\n",
        "print(\"Q3-1 criterion='gini': \", accuracy_score(y_val, dt_gini.predict(X_val)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1XG7eAKUQ-YU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q3-2 criterion='entropy':  0.77\n"
          ]
        }
      ],
      "source": [
        "# For Q3-2, validation accuracy should be higher than or equal to 0.77\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "dt_entropy = DecisionTree(criterion='entropy', max_features=None, max_depth=3)\n",
        "dt_entropy.fit(X_train, y_train, sample_weight=None)\n",
        "\n",
        "print(\"Q3-2 criterion='entropy': \", accuracy_score(y_val, dt_entropy.predict(X_val)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "joE89xabPsXg"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# For Q4\n",
        "import matplotlib.pyplot as plt\n",
        "np.random.seed(0)\n",
        "dtree = DecisionTree(criterion='gini', max_features=None, max_depth=10)\n",
        "dtree.fit(X_train, y_train, sample_weight=None)\n",
        "\n",
        "# Prepare importance for plotting\n",
        "dtree.countImportance()\n",
        "\n",
        "X_importance = []\n",
        "for i in range(X_train.shape[1]):\n",
        "    cond = i in dtree.importance.keys()\n",
        "    # print(i, cond, X.shape[1])\n",
        "    if cond:\n",
        "        X_importance += [dtree.importance[i]]\n",
        "    else:\n",
        "        X_importance += [0]\n",
        "\n",
        "# Use simply counting to get the feature importance: dt_depth10.importance\n",
        "labelList=['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5', 'Feature6', 'Feature7']\n",
        "\n",
        "plt.grid('major', linewidth=1, zorder=0)\n",
        "plt.bar(np.arange(len(X_importance)), X_importance, 0.7, zorder=2)\n",
        "\n",
        "\n",
        "plt.xticks(np.arange(len(labelList)), labelList)\n",
        "plt.title('Feature Importance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wg97qz_xUGfP"
      },
      "source": [
        "# Questions for Random Rorest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "SlrdIW1ERJ8F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q5-1 n_estimators=10:  0.8775\n"
          ]
        }
      ],
      "source": [
        "# For Q5-1, validation accuracy should be higher than or equal to 0.88\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "rf_estimators10 = RandomForest(n_estimators=10, max_features=np.sqrt(X_train.shape[1]), boostrap=True, criterion='gini', max_depth=None)\n",
        "rf_estimators10.fit(X_train, y_train)\n",
        "\n",
        "print(\"Q5-1 n_estimators=10: \", accuracy_score(y_val, rf_estimators10.predict(X_val)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "4qcLuIkbRUfM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q5-1 n_estimators=50:  0.89625\n"
          ]
        }
      ],
      "source": [
        "# For Q5-2, validation accuracy should be higher than or equal to 0.89\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "rf_estimators50 = RandomForest(n_estimators=50, max_features=np.sqrt(X_train.shape[1]), boostrap=True, criterion='gini', max_depth=None)\n",
        "rf_estimators50.fit(X_train, y_train)\n",
        "\n",
        "print(\"Q5-1 n_estimators=50: \", accuracy_score(y_val, rf_estimators50.predict(X_val)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "n-DbniYhRYmM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q6-1 max_features='sqrt':  0.8775\n"
          ]
        }
      ],
      "source": [
        "# For Q6-1, validation accuracy should be higher than or equal to 0.88\n",
        "\n",
        "np.random.seed(0)\n",
        "    \n",
        "rf_maxfeature_sqrt = RandomForest(n_estimators=10, max_features=np.sqrt(X_train.shape[1]), boostrap=True, criterion='gini', max_depth=None)\n",
        "rf_maxfeature_sqrt.fit(X_train, y_train)\n",
        "\n",
        "print(\"Q6-1 max_features='sqrt': \", accuracy_score(y_val,  rf_maxfeature_sqrt.predict(X_val)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "PF9yufSaRffn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q6-2 max_features='All':  0.87\n"
          ]
        }
      ],
      "source": [
        "# For Q6-2, validation accuracy should be higher than or equal to 0.86\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "rf_maxfeature_none = RandomForest(n_estimators=10, max_features=None, boostrap=True, criterion='gini', max_depth=None)\n",
        "rf_maxfeature_none.fit(X_train, y_train)\n",
        "\n",
        "print(\"Q6-2 max_features='All': \", accuracy_score(y_val, rf_maxfeature_none.predict(X_val)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjopdAZqUKbF"
      },
      "source": [
        "# Train your own model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "5cmxQjK3Rja9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation score:  0.90625\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "model = RandomForest(n_estimators=50, max_features=4, boostrap=True, criterion='gini', max_depth=15)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Validation score: \", accuracy_score(y_val, model.predict(X_val)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([6, 5, 3, 3, 3, 2, 6, 6, 6, 3, 0, 3, 3, 2, 4, 3, 0, 3, 4, 3, 2, 3,\n",
              "       4, 3, 3, 6, 5, 0, 3, 5, 1, 6, 5, 6, 3, 2, 3, 0, 0, 3, 5, 3, 0, 3,\n",
              "       3, 6, 4, 4, 3, 2, 5, 2, 3, 5, 6, 4, 5, 6, 5, 3, 3, 5, 3, 2, 4, 5,\n",
              "       0, 0, 6, 1, 6, 2, 5, 3, 3, 3, 2, 0, 0, 3, 5, 6, 1, 6, 5, 0, 6, 6,\n",
              "       6, 6, 0, 4, 3, 6, 4, 0, 4, 1, 6, 6, 5, 5, 2, 3, 2, 6, 6, 3, 6, 3,\n",
              "       1, 4, 5, 5, 3, 3, 3, 6, 5, 5, 1, 3, 1, 6, 2, 3, 6, 4, 3, 5, 2, 3,\n",
              "       6, 5, 4, 5, 3, 6, 3, 6, 0, 5, 6, 4, 0, 5, 6, 4, 5, 1, 6, 5, 3, 2,\n",
              "       6, 6, 2, 2, 6, 5, 0, 6, 0, 5, 6, 5, 6, 6, 3, 5, 6, 3, 6, 3, 5, 5,\n",
              "       6, 2, 6, 4, 0, 6, 0, 4, 4, 5, 6, 0, 5, 3, 4, 6, 3, 4, 3, 4, 3, 5,\n",
              "       0, 5, 4, 3, 4, 4, 3, 6, 0, 5, 5, 5, 6, 5, 4, 0, 0, 2, 5, 6, 4, 1,\n",
              "       0, 3, 6, 4, 6, 2, 5, 5, 4, 5, 2, 2, 5, 3, 3, 4, 6, 2, 5, 0, 3, 3,\n",
              "       4, 3, 4, 3, 3, 4, 2, 3, 5, 4, 0, 0, 3, 0, 1, 1, 6, 3, 6, 1, 6, 3,\n",
              "       3, 3, 5, 5, 4, 2, 3, 3, 3, 6, 3, 6, 5, 6, 3, 4, 6, 3, 2, 1, 2, 3,\n",
              "       3, 6, 3, 6, 3, 3, 5, 5, 3, 4, 3, 2, 6, 6, 0, 3, 6, 3, 3, 0, 0, 5,\n",
              "       2, 2, 3, 4, 3, 2, 5, 0, 6, 0, 0, 6, 1, 3, 4, 3, 0, 3, 2, 3, 2, 3,\n",
              "       2, 2, 2, 6, 5, 6, 2, 0, 3, 4, 0, 6, 4, 5, 3, 6, 4, 2, 4, 3, 3, 4,\n",
              "       4, 0, 3, 0, 3, 4, 3, 2, 6, 2, 4, 3, 4, 0, 3, 0, 5, 3, 2, 6, 3, 4,\n",
              "       4, 6, 0, 6, 5, 6, 3, 5, 6, 5, 0, 3, 6, 6, 4, 3, 2, 6, 2, 6, 6, 3,\n",
              "       2, 5, 3, 0, 3, 3, 6, 4, 3, 3, 5, 5, 6, 2, 0, 3, 3, 5, 3, 1, 3, 3,\n",
              "       3, 5, 6, 4, 0, 3, 3, 3, 4, 3, 1, 4, 3, 4, 4, 2, 3, 4, 3, 4, 5, 3,\n",
              "       0, 1, 5, 0, 3, 4, 6, 0, 3, 6, 6, 6, 3, 0, 3, 3, 3, 3, 5, 6, 3, 6,\n",
              "       6, 6, 5, 4, 2, 6, 3, 3, 4, 4, 5, 5, 4, 5, 4, 6, 0, 3, 3, 6, 1, 5,\n",
              "       3, 0, 3, 0, 3, 5, 3, 0, 2, 3, 5, 6, 4, 5, 4, 2, 5, 6, 2, 3, 6, 3,\n",
              "       3, 3, 6, 6, 3, 5, 0, 4, 5, 6, 0, 0, 5, 3, 6, 5, 3, 5, 0, 5, 0, 6,\n",
              "       2, 0, 6, 6, 2, 3, 4, 3, 6, 6, 3, 4, 6, 3, 5, 3, 3, 3, 5, 3, 6, 4,\n",
              "       0, 3, 1, 0, 0, 0, 2, 0, 5, 3, 4, 2, 4, 0, 0, 6, 3, 3, 5, 1, 3, 3,\n",
              "       2, 3, 3, 4, 6, 3, 5, 5, 4, 5, 4, 0, 4, 3, 5, 3, 3, 1, 5, 5, 4, 1,\n",
              "       3, 5, 0, 2, 0, 2, 6, 6, 6, 6, 5, 3, 3, 5, 0, 6, 4, 4, 1, 5, 3, 3,\n",
              "       2, 2, 0, 4, 3, 3, 3, 3, 5, 3, 2, 6, 0, 0, 2, 0, 3, 4, 1, 5, 3, 6,\n",
              "       3, 5, 2, 0, 5, 4, 3, 6, 3, 3, 0, 3, 3, 4, 3, 4, 6, 5, 3, 5, 4, 4,\n",
              "       2, 0, 6, 2, 4, 4, 3, 3, 2, 6, 2, 2, 0, 3, 0, 2, 0, 2, 4, 3, 5, 4,\n",
              "       3, 3, 6, 5, 3, 3, 2, 3, 2, 6, 4, 5, 3, 2, 2, 6, 4, 2, 3, 3, 2, 2,\n",
              "       6, 4, 2, 3, 6, 2, 3, 6, 3, 6, 5, 3, 3, 5, 6, 3, 3, 2, 3, 3, 3, 6,\n",
              "       4, 4, 3, 3, 1, 4, 2, 0, 3, 5, 6, 3, 6, 3, 3, 0, 3, 2, 1, 2, 3, 2,\n",
              "       5, 6, 6, 3, 4, 6, 2, 6, 3, 5, 5, 0, 3, 6, 3, 2, 3, 6, 6, 3, 3, 3,\n",
              "       4, 4, 4, 0, 3, 2, 6, 6, 4, 4, 0, 3, 5, 2, 0, 5, 6, 3, 3, 1, 2, 5,\n",
              "       6, 6, 6, 4, 5, 6, 0, 5])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_pred = model.predict(X_test)\n",
        "test_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "XCaZ4yFuR34B"
      },
      "outputs": [],
      "source": [
        "# output csv\n",
        "df_test = pd.DataFrame(pd.read_csv(\"./PR_HW3_Test.csv\"))\n",
        "df_test[\"Target\"] = test_pred\n",
        "df_test.to_csv(\"prediction.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train acc:  1.0\n"
          ]
        }
      ],
      "source": [
        "# Q Part 2.1\n",
        "np.random.seed(0) # You may adjust the seed number in all the cells\n",
        "\n",
        "dt_depth3 = DecisionTree(criterion='gini', max_features=None, max_depth=None)\n",
        "dt_depth3.fit(X_train, y_train, sample_weight=None)\n",
        "\n",
        "acc = accuracy_score(y_train, dt_depth3.predict(X_train))\n",
        "\n",
        "print(\"Train acc: \", acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A 1 0\n",
            "B 0 1\n",
            "A gini: 0.4444444444444444 0.0\n",
            "B gini: 0.375 0.375\n",
            "A entropy: 0.9182958311690995 -1.4426951595367387e-09\n",
            "B entropy: 0.8112781215737428 0.8112781215737428\n"
          ]
        }
      ],
      "source": [
        "# Q PART 2.3\n",
        "import numpy as np\n",
        "C1 = np.zeros(400)\n",
        "C2 = np.zeros(400) +1\n",
        "\n",
        "# Tree model A\n",
        "Aleaf_11 = (C1[:200], C2)\n",
        "Aleaf_12 = (C1[:200], C1[:0])\n",
        "\n",
        "# Tree model B\n",
        "Bleaf_11 = (C1[:300], C2[:100])\n",
        "Bleaf_12 = (C1[:100], C2[:300])\n",
        "\n",
        "Aleaf_11_c = np.concatenate(Aleaf_11)\n",
        "Aleaf_12_c = np.concatenate(Aleaf_12)\n",
        "\n",
        "Aleaf_11_class = np.argmax(np.bincount(Aleaf_11_c.astype(int)))\n",
        "Aleaf_12_class = np.argmax(np.bincount(Aleaf_12_c.astype(int)))\n",
        "print('A', Aleaf_11_class, Aleaf_12_class)\n",
        "\n",
        "Bleaf_11_c = np.concatenate(Bleaf_11)\n",
        "Bleaf_12_c = np.concatenate(Bleaf_12)\n",
        "\n",
        "Bleaf_11_class = np.argmax(np.bincount(Bleaf_11_c.astype(int)))\n",
        "Bleaf_12_class = np.argmax(np.bincount(Bleaf_12_c.astype(int)))\n",
        "print('B', Bleaf_11_class, Bleaf_12_class)\n",
        "################################################################\n",
        "print('A gini:', gini(Aleaf_11_c), gini(Aleaf_12_c))\n",
        "print('B gini:', gini(Bleaf_11_c), gini(Bleaf_12_c))\n",
        "\n",
        "print('A entropy:', entropy(Aleaf_11_c), entropy(Aleaf_12_c))\n",
        "print('B entropy:', entropy(Bleaf_11_c), entropy(Bleaf_12_c))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "YV1MHt_VTg9f"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
